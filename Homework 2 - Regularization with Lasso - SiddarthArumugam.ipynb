{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this homework, you'll be required to load in a dataset which has about 500 features. By using Lasso ($L^1$) regression, we'll find the optimal constraint on the $L^1$ norm which gives us the best $R^2$. Then we'll plot the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall we minimize the following on training data: $(x_i,y_i)$\n",
    "$$\\min_{\\beta} \\frac{1}{N} \\sum_{i=1}^N (y_i - \\beta \\cdot x_i)^2 + \\lambda \\|\\beta \\|_{L^1}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Denoting $\\beta_{\\lambda}$ as the minimum of the above, we then choose $\\lambda$ to maximize $R^2$ on testing data: $(x_j,y_j)$\n",
    "$$ \\max_{\\lambda} 1 - \\frac{\\sum_{j} (y_j - \\beta_{\\lambda} \\cdot x_j)^2}{\\sum_j (y_j - \\bar y)^2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Load in hw2data.csv from ../data into a pandas dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Set y to be the y variable in the dataframe from a and X to be the remaining features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) As shown in the Booking.com example, using Lasso regression, find the regularization strength\n",
    "which optimizes the $R^2$. \n",
    "\n",
    "**Hint:** Take a range of alpha from `np.logspace(-8,-3,1000)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Plot the training perforamnce versus the testing performance, and observe whree the test performance is\n",
    "maximized. I've written an outline of the code you need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt #old\n",
    "import numpy as np\n",
    "plt.subplot(2, 1, 1)\n",
    "\n",
    "# Fill these in\n",
    "alphas = []\n",
    "train_errors=[]\n",
    "test_errors=[]\n",
    "alpha_optim=0\n",
    "\n",
    "\n",
    "\n",
    "plt.semilogx(alphas, train_errors, label='Train')\n",
    "plt.semilogx(alphas, test_errors, label='Test')\n",
    "plt.vlines(alpha_optim, plt.ylim()[0], np.max(test_errors), color='k',\n",
    "           linewidth=3, label='Optimum on test')\n",
    "plt.legend(loc='lower left')\n",
    "plt.ylim([0, 1.2])\n",
    "plt.xlabel('Regularization parameter')\n",
    "plt.ylabel('Performance')\n",
    "\n",
    "# Show estimated coef_ vs true coef\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(coef, label='True coef')\n",
    "plt.plot(coef_, label='Estimated coef')\n",
    "plt.legend()\n",
    "plt.subplots_adjust(0.09, 0.04, 0.94, 0.94, 0.26, 0.26)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>491</th>\n",
       "      <th>492</th>\n",
       "      <th>493</th>\n",
       "      <th>494</th>\n",
       "      <th>495</th>\n",
       "      <th>496</th>\n",
       "      <th>497</th>\n",
       "      <th>498</th>\n",
       "      <th>499</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.382732</th>\n",
       "      <td>-0.034242</td>\n",
       "      <td>1.096347</td>\n",
       "      <td>-0.234216</td>\n",
       "      <td>-0.347451</td>\n",
       "      <td>-0.581268</td>\n",
       "      <td>-1.632635</td>\n",
       "      <td>-1.567768</td>\n",
       "      <td>-1.179158</td>\n",
       "      <td>1.301428</td>\n",
       "      <td>0.895260</td>\n",
       "      <td>...</td>\n",
       "      <td>0.178793</td>\n",
       "      <td>-0.799422</td>\n",
       "      <td>0.240788</td>\n",
       "      <td>0.289121</td>\n",
       "      <td>0.412871</td>\n",
       "      <td>-0.198399</td>\n",
       "      <td>0.094192</td>\n",
       "      <td>-1.147611</td>\n",
       "      <td>-0.358114</td>\n",
       "      <td>-2.663126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.555963</th>\n",
       "      <td>0.892474</td>\n",
       "      <td>-0.422315</td>\n",
       "      <td>0.104714</td>\n",
       "      <td>0.228053</td>\n",
       "      <td>0.201480</td>\n",
       "      <td>0.540774</td>\n",
       "      <td>-1.818078</td>\n",
       "      <td>-0.049324</td>\n",
       "      <td>0.239034</td>\n",
       "      <td>-1.000330</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.740137</td>\n",
       "      <td>-0.565498</td>\n",
       "      <td>0.476031</td>\n",
       "      <td>-2.158069</td>\n",
       "      <td>1.318551</td>\n",
       "      <td>-0.239297</td>\n",
       "      <td>-0.246794</td>\n",
       "      <td>-1.079343</td>\n",
       "      <td>-0.114226</td>\n",
       "      <td>10.399650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.013240</th>\n",
       "      <td>-0.121945</td>\n",
       "      <td>0.339059</td>\n",
       "      <td>-0.589632</td>\n",
       "      <td>-0.895816</td>\n",
       "      <td>0.548328</td>\n",
       "      <td>0.098667</td>\n",
       "      <td>0.197181</td>\n",
       "      <td>1.059027</td>\n",
       "      <td>-1.022564</td>\n",
       "      <td>-0.855240</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.739936</td>\n",
       "      <td>1.315138</td>\n",
       "      <td>-0.323457</td>\n",
       "      <td>0.197828</td>\n",
       "      <td>0.097751</td>\n",
       "      <td>1.401523</td>\n",
       "      <td>0.158434</td>\n",
       "      <td>-1.141901</td>\n",
       "      <td>-1.310970</td>\n",
       "      <td>-21.762801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-1.532921</th>\n",
       "      <td>-1.711970</td>\n",
       "      <td>0.046135</td>\n",
       "      <td>-0.958374</td>\n",
       "      <td>-0.080812</td>\n",
       "      <td>-0.703859</td>\n",
       "      <td>-0.770784</td>\n",
       "      <td>-0.480845</td>\n",
       "      <td>0.703586</td>\n",
       "      <td>0.929145</td>\n",
       "      <td>0.371173</td>\n",
       "      <td>...</td>\n",
       "      <td>0.473488</td>\n",
       "      <td>1.855246</td>\n",
       "      <td>1.415656</td>\n",
       "      <td>-0.302746</td>\n",
       "      <td>0.989679</td>\n",
       "      <td>0.585851</td>\n",
       "      <td>1.136388</td>\n",
       "      <td>0.671617</td>\n",
       "      <td>-0.974167</td>\n",
       "      <td>2.139453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-1.619685</th>\n",
       "      <td>0.572627</td>\n",
       "      <td>1.902618</td>\n",
       "      <td>-0.775664</td>\n",
       "      <td>-0.188090</td>\n",
       "      <td>-1.035748</td>\n",
       "      <td>1.177830</td>\n",
       "      <td>-2.305167</td>\n",
       "      <td>-2.263660</td>\n",
       "      <td>0.375020</td>\n",
       "      <td>-0.082344</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.303220</td>\n",
       "      <td>0.466751</td>\n",
       "      <td>0.161106</td>\n",
       "      <td>0.320032</td>\n",
       "      <td>2.079177</td>\n",
       "      <td>-0.907466</td>\n",
       "      <td>-0.192404</td>\n",
       "      <td>-1.212516</td>\n",
       "      <td>-0.080599</td>\n",
       "      <td>0.194017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 500 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  1         2         3         4         5         6  \\\n",
       "0                                                                       \n",
       " 0.382732 -0.034242  1.096347 -0.234216 -0.347451 -0.581268 -1.632635   \n",
       " 0.555963  0.892474 -0.422315  0.104714  0.228053  0.201480  0.540774   \n",
       " 0.013240 -0.121945  0.339059 -0.589632 -0.895816  0.548328  0.098667   \n",
       "-1.532921 -1.711970  0.046135 -0.958374 -0.080812 -0.703859 -0.770784   \n",
       "-1.619685  0.572627  1.902618 -0.775664 -0.188090 -1.035748  1.177830   \n",
       "\n",
       "                  7         8         9        10    ...           491  \\\n",
       "0                                                    ...                 \n",
       " 0.382732 -1.567768 -1.179158  1.301428  0.895260    ...      0.178793   \n",
       " 0.555963 -1.818078 -0.049324  0.239034 -1.000330    ...     -0.740137   \n",
       " 0.013240  0.197181  1.059027 -1.022564 -0.855240    ...     -0.739936   \n",
       "-1.532921 -0.480845  0.703586  0.929145  0.371173    ...      0.473488   \n",
       "-1.619685 -2.305167 -2.263660  0.375020 -0.082344    ...     -1.303220   \n",
       "\n",
       "                492       493       494       495       496       497  \\\n",
       "0                                                                       \n",
       " 0.382732 -0.799422  0.240788  0.289121  0.412871 -0.198399  0.094192   \n",
       " 0.555963 -0.565498  0.476031 -2.158069  1.318551 -0.239297 -0.246794   \n",
       " 0.013240  1.315138 -0.323457  0.197828  0.097751  1.401523  0.158434   \n",
       "-1.532921  1.855246  1.415656 -0.302746  0.989679  0.585851  1.136388   \n",
       "-1.619685  0.466751  0.161106  0.320032  2.079177 -0.907466 -0.192404   \n",
       "\n",
       "                498       499          y  \n",
       "0                                         \n",
       " 0.382732 -1.147611 -0.358114  -2.663126  \n",
       " 0.555963 -1.079343 -0.114226  10.399650  \n",
       " 0.013240 -1.141901 -1.310970 -21.762801  \n",
       "-1.532921  0.671617 -0.974167   2.139453  \n",
       "-1.619685 -1.212516 -0.080599   0.194017  \n",
       "\n",
       "[5 rows x 500 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import pylab as plt\n",
    "import seaborn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy.random as nprnd\n",
    "import random\n",
    "import json\n",
    "\n",
    "df = pd.read_csv('hw2data.csv', index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       " 0.382732    -2.663126\n",
       " 0.555963    10.399650\n",
       " 0.013240   -21.762801\n",
       "-1.532921     2.139453\n",
       "-1.619685     0.194017\n",
       "Name: y, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df['y']\n",
    "x = df.drop('y',1)\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.subplot(2, 1, 1)\n",
    "\n",
    "# Fill these in\n",
    "alphas = []\n",
    "train_errors=[]\n",
    "test_errors=[]\n",
    "alpha_optim=0\n",
    "\n",
    "\n",
    "\n",
    "plt.semilogx(alphas, train_errors, label='Train')\n",
    "plt.semilogx(alphas, test_errors, label='Test')\n",
    "plt.vlines(alpha_optim, plt.ylim()[0], np.max(test_errors), color='k',\n",
    "           linewidth=3, label='Optimum on test')\n",
    "plt.legend(loc='lower left')\n",
    "plt.ylim([0, 1.2])\n",
    "plt.xlabel('Regularization parameter')\n",
    "plt.ylabel('Performance')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e) Plot the top coefficients based on this optimal paramter. Why do you think so many are zero? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f) Compute the $R^2$ with the optimal coefficient found above on 5 folds using cross_val_score and plot the\n",
    "results. Does the model work well on all random subsets?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f) Repeat e) but using cross validation. Use error bars on the features which are the standard deviation of the \n",
    "coefficiens obtained above. For this problem I\"ll walk you through the code. You just need to apply your optimal\n",
    "$\\alpha$ found above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import KFold #old\n",
    "def run_cv_coeffs(X,y,clf_class,**kwargs):\n",
    "    # Construct a kfolds object\n",
    "    kf = KFold(len(y),n_folds=5,shuffle=True)\n",
    "    y_pred = y.copy()\n",
    "    coeffs=[]\n",
    "    # Iterate through folds\n",
    "    for train_index, test_index in kf:\n",
    "        \n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train = y[train_index]\n",
    "        # Initialize a classifier with key word arguments\n",
    "        clf = clf_class(**kwargs)\n",
    "        clf.fit(X_train,y_train)\n",
    "        y_pred[test_index] = clf.predict(X_test)\n",
    "        coeffs.append(clf.coef_)\n",
    "    return coeffs\n",
    "\n",
    "\n",
    "from sklearn import preprocessing\n",
    "scaler = preprocessing.StandardScaler()\n",
    "X2 = X.as_matrix().astype(np.float)\n",
    "X2 = scaler.fit_transform(X)\n",
    "\n",
    "coeffs=run_cv_coeffs(X2,np.array(y),Lasso,alpha=alpha_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import KFold\n",
    "from sklearn import preprocessing\n",
    "def run_cv_coeffs(X,y,clf_class,**kwargs):\n",
    "    # Construct a kfolds object\n",
    "    kf = KFold(len(y),n_folds=5,shuffle=True)\n",
    "    y_pred = y.copy()\n",
    "    coeffs=[]\n",
    "    # Iterate through folds\n",
    "    for train_index, test_index in kf:\n",
    "        \n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train = y[train_index]\n",
    "        # Initialize a classifier with key word arguments\n",
    "        clf = clf_class(**kwargs)\n",
    "        clf.fit(X_train,y_train)\n",
    "        y_pred[test_index] = clf.predict(X_test)\n",
    "        coeffs.append(clf.coef_)\n",
    "    return coeffs\n",
    "\n",
    "\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "X_scaled = X.as_matrix().astype(np.float)\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "coeffs=run_cv_coeffs(X_scaled,np.array(y),Lasso,alpha=alpha_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_coeffs(coeffs):\n",
    "    coeffs_avgd = [(coeffs[0][i] + coeffs[1][i] + coeffs[2][i] + coeffs[3][i] + coeffs[4][i])/5 for i in range(0,len(X.columns))]\n",
    "    coeffs_std = [np.std([coeffs[0][i],coeffs[1][i],coeffs[2][i],coeffs[3][i],coeffs[4][i]]) for i in range(0,len(X.columns))]\n",
    "    return coeffs_avgd, coeffs_std\n",
    "coeffs_avg,coeffs_std=get_coeffs(coeffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x16ef6d090>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dfCoeffs = pd.DataFrame({'type':X.columns.values, 'coef':coeffs_avg, 'std':coeffs_std})\n",
    "dfCoeffs = dfCoeffs[(dfCoeffs['coef']>1) |(dfCoeffs['coef']<-1) ]\n",
    "plt.figure(figsize=(15,15))\n",
    "dfCoeffs_sorted = dfCoeffs.sort(['coef'])[::-1]\n",
    "yerr_vals = dfCoeffs_sorted['std'].values\n",
    "dfCoeffs_sorted.plot(x='type',y='coef',kind='bar',yerr=yerr_vals,figsize=(15,15))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
